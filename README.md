# DATATHON - Fase 5 - P√≥s Tech Data Analytics - FIAP - RM360405

## Descri√ß√£o do projeto

Este projeto tem como objetivo construir um sistema de recomenda√ß√£o de candidatos para vagas de emprego utilizando t√©cnicas de processamento de linguagem natural (NLP) e aprendizado de m√°quina. O sistema analisa informa√ß√µes detalhadas dos candidatos e das vagas, gera embeddings textuais para os perfis e realiza c√°lculo de similaridade para indicar os candidatos mais adequados para cada vaga.

## Streamlit  
üîó [Link da aplica√ß√£o no Streamlit](https://data-analytics-postech-fase05.streamlit.app)

## Youtube  
üé• [Link do v√≠deo no Youtube](https://youtu.be/BPD_oQ_02zk)

## Stack utilizada

- Python 3
- Bibliotecas: pandas, numpy, matplotlib, seaborn, re, datetime, warnings
- NLP e embeddings: Sentence-Transformers (`paraphrase-multilingual-MiniLM-L12-v2``)
- Machine Learning: scikit-learn (train_test_split, m√©tricas, cosine_similarity)
- Outras: pickle para serializa√ß√£o, huggingface_hub para autentica√ß√£o e carregamento de modelos

## Como rodar o app localmente

1. Clone o reposit√≥rio do projeto.
2. Certifique-se de ter os arquivos JSON de dados (`applicants.json`, `vagas.json`, `prospects.json`) na pasta do projeto.
3. Instale as depend√™ncias necess√°rias com: `pip install -r requirements.txt`
4. Execute o notebook ou o script Python principal que cont√©m o pipeline completo para carregar os dados, process√°-los, gerar embeddings, treinar o modelo e realizar recomenda√ß√µes.
5. O sistema ir√° gerar arquivos de modelo serializados para uso futuro e permitir√° testar recomenda√ß√µes para vagas espec√≠ficas.

## Instru√ß√µes de instala√ß√£o

- Instale o Python 3.7 ou superior.
- Instale as bibliotecas necess√°rias executando: `pip install numpy pandas matplotlib seaborn scikit-learn sentence-transformers`
- Tenha os arquivos JSON de dados necess√°rios no diret√≥rio do projeto.

## Como treinar o modelo novamente

1. Prepare os dados JSON dos candidatos, vagas e prospects.
2. Execute o c√≥digo para carregar e pr√©-processar os dados (tratamento, limpeza e normaliza√ß√£o).
3. Gere embeddings para os perfis dos candidatos e das vagas usando os modelos Sentence-Transformer pr√©-treinados.
4. Aplique os pesos sobre os embeddings conforme definido para cada grupo de caracter√≠sticas.
5. Fa√ßa o merge dos dados para preparar os pares candidatos-vagas para o treinamento.
6. Treine o modelo utilizando os embeddings processados, calculando a similaridade de cosseno para recomenda√ß√µes.
7. Serialize os dataframes finais com os embeddings para uso futuro, salvando-os em arquivos `.pkl` com `pickle`.

## Arquivos neste diret√≥rio do Github  
- **Bases**: Pasta com os arquivos em `.json` utilizados para an√°lise e treinamento
- **Embeddings**: Dataframes finais com os embedding para utilizar na aplica√ß√£o web
- **Notebook do Machine Learning**: Cont√©m o Notebook utilizado para desenvolvimento do processamento dos dados e treinamento dos embeddings processados.





